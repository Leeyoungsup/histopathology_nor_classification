{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import torchmetrics\n",
    "import timm\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1\n",
    "image_count=50\n",
    "img_size=512\n",
    "tf = ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "\n",
    "        self.label = label_list\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor = torch.empty((image_count,3, img_size, img_size))\n",
    "        \n",
    "        image_file_list = glob(self.img_path[idx]+'/*.jpg')\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-1, size=(image_count,))\n",
    "        count = 0\n",
    "        for index in image_index:\n",
    "            image = 1-tf(Image.open(image_file_list[index]))\n",
    "            image_tensor[count] = image\n",
    "            count += 1\n",
    "        label_tensor =  self.label[idx]\n",
    "        return image_tensor, label_tensor\n",
    "    \n",
    "train_image_transition_path='../../data/dataset/gcu/MMRd/train/Defect/*'\n",
    "train_image_not_transition_path='../../data/dataset/gcu/MMRd/train/Normal/*'\n",
    "test_image_transition_path='../../data/dataset/gcu/MMRd/test/Defect/*'\n",
    "test_image_not_transition_path='../../data/dataset/gcu/MMRd/test/Normal/*'\n",
    "\n",
    "train_image_list = []\n",
    "train_label_list = []\n",
    "image_abnormal_list = glob(train_image_transition_path)\n",
    "image_abnormal_label = torch.ones(len(image_abnormal_list), 1)\n",
    "image_normal_list = glob(train_image_not_transition_path)\n",
    "image_normal_label = torch.zeros(len(image_normal_list), 1)\n",
    "train_image_list.extend(image_abnormal_list)\n",
    "train_image_list.extend(image_abnormal_list)\n",
    "train_image_list.extend(image_abnormal_list)\n",
    "train_image_list.extend(image_normal_list)\n",
    "train_label_list.extend(image_abnormal_label)\n",
    "train_label_list.extend(image_abnormal_label)\n",
    "train_label_list.extend(image_abnormal_label)\n",
    "train_label_list.extend(image_normal_label)\n",
    "\n",
    "test_image_list = []\n",
    "test_label_list = []\n",
    "image_abnormal_list = glob(test_image_transition_path)\n",
    "image_abnormal_label = torch.ones(len(image_abnormal_list), 1)\n",
    "image_normal_list = glob(test_image_not_transition_path)\n",
    "image_normal_label = torch.zeros(len(image_normal_list), 1)\n",
    "test_image_list.extend(image_abnormal_list)\n",
    "test_image_list.extend(image_abnormal_list)\n",
    "test_image_list.extend(image_abnormal_list)\n",
    "test_image_list.extend(image_normal_list)\n",
    "test_label_list.extend(image_abnormal_label)\n",
    "test_label_list.extend(image_abnormal_label)\n",
    "test_label_list.extend(image_abnormal_label)\n",
    "test_label_list.extend(image_normal_label)\n",
    "train_image_list.extend(test_image_list)\n",
    "train_label_list.extend(test_label_list)\n",
    "train_dataset = CustomDataset(train_image_list, F.one_hot(torch.tensor(train_label_list).to(torch.int64)))\n",
    "\n",
    "test_dataset = CustomDataset(test_image_list, F.one_hot(torch.tensor(test_label_list).to(torch.int64)))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "AttentionMILModel                                       [1, 2]                    --\n",
       "├─FeatureExtractor: 1-1                                 [50, 1408]                --\n",
       "│    └─Sequential: 2-1                                  [50, 1408]                --\n",
       "│    │    └─Conv2d: 3-1                                 [50, 32, 256, 256]        864\n",
       "│    │    └─BatchNormAct2d: 3-2                         [50, 32, 256, 256]        64\n",
       "│    │    └─Sequential: 3-3                             [50, 352, 16, 16]         7,201,634\n",
       "│    │    └─Conv2d: 3-4                                 [50, 1408, 16, 16]        495,616\n",
       "│    │    └─BatchNormAct2d: 3-5                         [50, 1408, 16, 16]        2,816\n",
       "│    │    └─SelectAdaptivePool2d: 3-6                   [50, 1408]                --\n",
       "├─Sequential: 1-2                                       [1, 50, 1]                --\n",
       "│    └─Linear: 2-2                                      [1, 50, 128]              180,352\n",
       "│    └─Tanh: 2-3                                        [1, 50, 128]              --\n",
       "│    └─Linear: 2-4                                      [1, 50, 1]                129\n",
       "├─Linear: 1-3                                           [1, 2]                    2,818\n",
       "=========================================================================================================\n",
       "Total params: 7,884,293\n",
       "Trainable params: 7,884,293\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 171.49\n",
       "=========================================================================================================\n",
       "Input size (MB): 157.29\n",
       "Forward/backward pass size (MB): 20469.83\n",
       "Params size (MB): 31.27\n",
       "Estimated Total Size (MB): 20658.38\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('efficientnet_b2', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "class AttentionMILModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(AttentionMILModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(image_feature_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_tiles, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Flatten the inputs\n",
    "        inputs = inputs.view(-1, channels, height, width)\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size * num_tiles, 2048, 1, 1)\n",
    "        \n",
    "        # Reshape features\n",
    "        features = features.view(batch_size, num_tiles, -1)  # Shape: (batch_size, num_tiles, 2048)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(features)  # Shape: (batch_size, num_tiles, 1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)  # Normalize attention weights\n",
    "        \n",
    "        # Apply attention weights to features\n",
    "        attended_features = torch.sum(features * attention_weights, dim=1)  # Shape: (batch_size, 2048)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(attended_features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits  \n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = AttentionMILModel(2,1408,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=2e-3, momentum=0.9)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(device)\n",
    "summary(model,(batch_size,image_count,3,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/1000 Step: 1293 loss : 0.3482 accuracy: 0.4930: 100%|██████████| 1292/1292 [28:44<00:00,  1.33s/it]\n",
      "Validation epoch: 1/1000 Step: 134 loss : 0.3445  accuracy: 0.4436: 100%|██████████| 133/133 [01:20<00:00,  1.65it/s]\n",
      "epoch: 2/1000 Step: 1293 loss : 0.3428 accuracy: 0.4791: 100%|██████████| 1292/1292 [29:26<00:00,  1.37s/it]\n",
      "Validation epoch: 2/1000 Step: 134 loss : 0.3447  accuracy: 0.4737: 100%|██████████| 133/133 [01:24<00:00,  1.58it/s]\n",
      "epoch: 3/1000 Step: 1293 loss : 0.3423 accuracy: 0.5279: 100%|██████████| 1292/1292 [29:48<00:00,  1.38s/it]\n",
      "Validation epoch: 3/1000 Step: 134 loss : 0.3445  accuracy: 0.4436: 100%|██████████| 133/133 [01:18<00:00,  1.70it/s]\n",
      "epoch: 4/1000 Step: 1293 loss : 0.3419 accuracy: 0.5108: 100%|██████████| 1292/1292 [31:43<00:00,  1.47s/it]\n",
      "Validation epoch: 4/1000 Step: 134 loss : 0.3441  accuracy: 0.4737: 100%|██████████| 133/133 [01:34<00:00,  1.41it/s]\n",
      "epoch: 5/1000 Step: 1293 loss : 0.3417 accuracy: 0.5364: 100%|██████████| 1292/1292 [30:08<00:00,  1.40s/it]\n",
      "Validation epoch: 5/1000 Step: 134 loss : 0.3449  accuracy: 0.4812: 100%|██████████| 133/133 [01:23<00:00,  1.58it/s]\n",
      "epoch: 6/1000 Step: 1293 loss : 0.3409 accuracy: 0.5480: 100%|██████████| 1292/1292 [29:34<00:00,  1.37s/it]\n",
      "Validation epoch: 6/1000 Step: 134 loss : 0.3446  accuracy: 0.4737: 100%|██████████| 133/133 [01:36<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/1000 Step: 1293 loss : 0.3397 accuracy: 0.5728: 100%|██████████| 1292/1292 [29:25<00:00,  1.37s/it]\n",
      "Validation epoch: 7/1000 Step: 134 loss : 0.3449  accuracy: 0.4436: 100%|██████████| 133/133 [01:16<00:00,  1.75it/s]\n",
      "epoch: 8/1000 Step: 1293 loss : 0.3381 accuracy: 0.5921: 100%|██████████| 1292/1292 [29:26<00:00,  1.37s/it]\n",
      "Validation epoch: 8/1000 Step: 134 loss : 0.3480  accuracy: 0.5038: 100%|██████████| 133/133 [01:28<00:00,  1.50it/s]\n",
      "epoch: 9/1000 Step: 1293 loss : 0.3307 accuracy: 0.6579: 100%|██████████| 1292/1292 [29:27<00:00,  1.37s/it]\n",
      "Validation epoch: 9/1000 Step: 134 loss : 0.3450  accuracy: 0.5263: 100%|██████████| 133/133 [01:24<00:00,  1.58it/s]\n",
      "epoch: 10/1000 Step: 1293 loss : 0.3137 accuracy: 0.7020: 100%|██████████| 1292/1292 [29:53<00:00,  1.39s/it]\n",
      "Validation epoch: 10/1000 Step: 134 loss : 0.3416  accuracy: 0.5188: 100%|██████████| 133/133 [01:23<00:00,  1.59it/s]\n",
      "epoch: 11/1000 Step: 1293 loss : 0.2860 accuracy: 0.7322: 100%|██████████| 1292/1292 [29:07<00:00,  1.35s/it]\n",
      "Validation epoch: 11/1000 Step: 134 loss : 0.3577  accuracy: 0.4812: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n",
      "epoch: 12/1000 Step: 1293 loss : 0.2631 accuracy: 0.7724: 100%|██████████| 1292/1292 [29:14<00:00,  1.36s/it]\n",
      "Validation epoch: 12/1000 Step: 134 loss : 0.3273  accuracy: 0.6316: 100%|██████████| 133/133 [01:25<00:00,  1.55it/s]\n",
      "epoch: 13/1000 Step: 1293 loss : 0.2457 accuracy: 0.8119: 100%|██████████| 1292/1292 [29:22<00:00,  1.36s/it]\n",
      "Validation epoch: 13/1000 Step: 134 loss : 0.3674  accuracy: 0.5038: 100%|██████████| 133/133 [01:12<00:00,  1.84it/s]\n",
      "epoch: 14/1000 Step: 1293 loss : 0.2281 accuracy: 0.8429: 100%|██████████| 1292/1292 [29:14<00:00,  1.36s/it]\n",
      "Validation epoch: 14/1000 Step: 134 loss : 0.3574  accuracy: 0.5263: 100%|██████████| 133/133 [01:13<00:00,  1.81it/s]\n",
      "epoch: 15/1000 Step: 1293 loss : 0.2252 accuracy: 0.8522: 100%|██████████| 1292/1292 [27:49<00:00,  1.29s/it]\n",
      "Validation epoch: 15/1000 Step: 134 loss : 0.3580  accuracy: 0.5338: 100%|██████████| 133/133 [01:08<00:00,  1.94it/s]\n",
      "epoch: 16/1000 Step: 1293 loss : 0.2160 accuracy: 0.8661: 100%|██████████| 1292/1292 [27:26<00:00,  1.27s/it]\n",
      "Validation epoch: 16/1000 Step: 134 loss : 0.3353  accuracy: 0.5865: 100%|██████████| 133/133 [01:05<00:00,  2.04it/s]\n",
      "epoch: 17/1000 Step: 1293 loss : 0.2022 accuracy: 0.8971: 100%|██████████| 1292/1292 [27:30<00:00,  1.28s/it]\n",
      "Validation epoch: 17/1000 Step: 134 loss : 0.3401  accuracy: 0.6165: 100%|██████████| 133/133 [01:10<00:00,  1.89it/s]\n",
      "epoch: 18/1000 Step: 1293 loss : 0.1971 accuracy: 0.9087: 100%|██████████| 1292/1292 [27:38<00:00,  1.28s/it]\n",
      "Validation epoch: 18/1000 Step: 134 loss : 0.3712  accuracy: 0.5338: 100%|██████████| 133/133 [01:09<00:00,  1.91it/s]\n",
      "epoch: 19/1000 Step: 1293 loss : 0.1888 accuracy: 0.9319: 100%|██████████| 1292/1292 [27:38<00:00,  1.28s/it]\n",
      "Validation epoch: 19/1000 Step: 134 loss : 0.3745  accuracy: 0.4812: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n",
      "epoch: 20/1000 Step: 1293 loss : 0.1826 accuracy: 0.9443: 100%|██████████| 1292/1292 [27:56<00:00,  1.30s/it]\n",
      "Validation epoch: 20/1000 Step: 134 loss : 0.3778  accuracy: 0.4962: 100%|██████████| 133/133 [01:07<00:00,  1.97it/s]\n",
      "epoch: 21/1000 Step: 1293 loss : 0.1757 accuracy: 0.9567: 100%|██████████| 1292/1292 [27:50<00:00,  1.29s/it]\n",
      "Validation epoch: 21/1000 Step: 134 loss : 0.3728  accuracy: 0.5038: 100%|██████████| 133/133 [01:11<00:00,  1.86it/s]\n",
      "epoch: 22/1000 Step: 1293 loss : 0.1740 accuracy: 0.9590: 100%|██████████| 1292/1292 [27:56<00:00,  1.30s/it]\n",
      "Validation epoch: 22/1000 Step: 134 loss : 0.3388  accuracy: 0.5639: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n",
      "epoch: 23/1000 Step: 1293 loss : 0.1725 accuracy: 0.9652: 100%|██████████| 1292/1292 [27:20<00:00,  1.27s/it]\n",
      "Validation epoch: 23/1000 Step: 134 loss : 0.3160  accuracy: 0.6692: 100%|██████████| 133/133 [01:15<00:00,  1.76it/s]\n",
      "epoch: 24/1000 Step: 1293 loss : 0.1710 accuracy: 0.9659: 100%|██████████| 1292/1292 [27:59<00:00,  1.30s/it]\n",
      "Validation epoch: 24/1000 Step: 134 loss : 0.3674  accuracy: 0.5038: 100%|██████████| 133/133 [01:17<00:00,  1.71it/s]\n",
      "epoch: 25/1000 Step: 1293 loss : 0.1661 accuracy: 0.9791: 100%|██████████| 1292/1292 [27:32<00:00,  1.28s/it]\n",
      "Validation epoch: 25/1000 Step: 134 loss : 0.3356  accuracy: 0.5714: 100%|██████████| 133/133 [01:13<00:00,  1.82it/s]\n",
      "epoch: 26/1000 Step: 1293 loss : 0.1656 accuracy: 0.9799: 100%|██████████| 1292/1292 [27:22<00:00,  1.27s/it]\n",
      "Validation epoch: 26/1000 Step: 134 loss : 0.3833  accuracy: 0.4586: 100%|██████████| 133/133 [01:11<00:00,  1.87it/s]\n",
      "epoch: 27/1000 Step: 1293 loss : 0.1636 accuracy: 0.9814: 100%|██████████| 1292/1292 [26:39<00:00,  1.24s/it]\n",
      "Validation epoch: 27/1000 Step: 134 loss : 0.3834  accuracy: 0.4887: 100%|██████████| 133/133 [01:05<00:00,  2.02it/s]\n",
      "epoch: 28/1000 Step: 1293 loss : 0.1628 accuracy: 0.9837: 100%|██████████| 1292/1292 [26:24<00:00,  1.23s/it]\n",
      "Validation epoch: 28/1000 Step: 134 loss : 0.3635  accuracy: 0.5188: 100%|██████████| 133/133 [01:04<00:00,  2.06it/s]\n",
      "epoch: 29/1000 Step: 1293 loss : 0.1637 accuracy: 0.9814: 100%|██████████| 1292/1292 [26:18<00:00,  1.22s/it]\n",
      "Validation epoch: 29/1000 Step: 134 loss : 0.3534  accuracy: 0.5564: 100%|██████████| 133/133 [01:04<00:00,  2.06it/s]\n",
      "epoch: 30/1000 Step: 1293 loss : 0.1606 accuracy: 0.9868: 100%|██████████| 1292/1292 [26:10<00:00,  1.22s/it]\n",
      "Validation epoch: 30/1000 Step: 134 loss : 0.3435  accuracy: 0.5639: 100%|██████████| 133/133 [01:08<00:00,  1.93it/s]\n",
      "epoch: 31/1000 Step: 1293 loss : 0.1611 accuracy: 0.9876: 100%|██████████| 1292/1292 [25:38<00:00,  1.19s/it]\n",
      "Validation epoch: 31/1000 Step: 134 loss : 0.3713  accuracy: 0.5113: 100%|██████████| 133/133 [01:06<00:00,  2.00it/s]\n",
      "epoch: 32/1000 Step: 1293 loss : 0.1592 accuracy: 0.9930: 100%|██████████| 1292/1292 [25:50<00:00,  1.20s/it]\n",
      "Validation epoch: 32/1000 Step: 134 loss : 0.3767  accuracy: 0.5188: 100%|██████████| 133/133 [01:06<00:00,  2.01it/s]\n",
      "epoch: 33/1000 Step: 1293 loss : 0.1602 accuracy: 0.9892: 100%|██████████| 1292/1292 [25:05<00:00,  1.16s/it]\n",
      "Validation epoch: 33/1000 Step: 134 loss : 0.3921  accuracy: 0.5038: 100%|██████████| 133/133 [01:08<00:00,  1.95it/s]\n",
      "epoch: 34/1000 Step: 1293 loss : 0.1584 accuracy: 0.9930: 100%|██████████| 1292/1292 [24:57<00:00,  1.16s/it]\n",
      "Validation epoch: 34/1000 Step: 134 loss : 0.3833  accuracy: 0.5564: 100%|██████████| 133/133 [01:05<00:00,  2.03it/s]\n",
      "epoch: 35/1000 Step: 1293 loss : 0.1589 accuracy: 0.9915: 100%|██████████| 1292/1292 [24:54<00:00,  1.16s/it]\n",
      "Validation epoch: 35/1000 Step: 134 loss : 0.3909  accuracy: 0.5263: 100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n",
      "epoch: 36/1000 Step: 1293 loss : 0.1575 accuracy: 0.9954: 100%|██████████| 1292/1292 [28:00<00:00,  1.30s/it]\n",
      "Validation epoch: 36/1000 Step: 134 loss : 0.3854  accuracy: 0.4887: 100%|██████████| 133/133 [01:15<00:00,  1.76it/s]\n",
      "epoch: 37/1000 Step: 1293 loss : 0.1583 accuracy: 0.9915: 100%|██████████| 1292/1292 [28:44<00:00,  1.33s/it]\n",
      "Validation epoch: 37/1000 Step: 134 loss : 0.4154  accuracy: 0.4887: 100%|██████████| 133/133 [01:07<00:00,  1.97it/s]\n",
      "epoch: 38/1000 Step: 1293 loss : 0.1586 accuracy: 0.9907: 100%|██████████| 1292/1292 [28:23<00:00,  1.32s/it]\n",
      "Validation epoch: 38/1000 Step: 134 loss : 0.3491  accuracy: 0.5639: 100%|██████████| 133/133 [01:14<00:00,  1.79it/s]\n",
      "epoch: 39/1000 Step: 1293 loss : 0.1573 accuracy: 0.9954: 100%|██████████| 1292/1292 [32:58<00:00,  1.53s/it]\n",
      "Validation epoch: 39/1000 Step: 134 loss : 0.3982  accuracy: 0.4962: 100%|██████████| 133/133 [01:34<00:00,  1.41it/s]\n",
      "epoch: 40/1000 Step: 1293 loss : 0.1569 accuracy: 0.9954: 100%|██████████| 1292/1292 [33:22<00:00,  1.55s/it]\n",
      "Validation epoch: 40/1000 Step: 134 loss : 0.3683  accuracy: 0.5188: 100%|██████████| 133/133 [01:56<00:00,  1.14it/s]\n",
      "epoch: 41/1000 Step: 1293 loss : 0.1562 accuracy: 0.9977: 100%|██████████| 1292/1292 [54:42<00:00,  2.54s/it]\n",
      "Validation epoch: 41/1000 Step: 134 loss : 0.3535  accuracy: 0.5414: 100%|██████████| 133/133 [01:46<00:00,  1.25it/s]\n",
      "epoch: 42/1000 Step: 1293 loss : 0.1568 accuracy: 0.9961: 100%|██████████| 1292/1292 [32:44<00:00,  1.52s/it]\n",
      "Validation epoch: 42/1000 Step: 134 loss : 0.3557  accuracy: 0.5489: 100%|██████████| 133/133 [01:29<00:00,  1.48it/s]\n",
      "epoch: 43/1000 Step: 1293 loss : 0.1562 accuracy: 0.9961: 100%|██████████| 1292/1292 [35:34<00:00,  1.65s/it]\n",
      "Validation epoch: 43/1000 Step: 134 loss : 0.3767  accuracy: 0.5263: 100%|██████████| 133/133 [01:38<00:00,  1.35it/s]\n",
      "epoch: 44/1000 Step: 1293 loss : 0.1575 accuracy: 0.9938: 100%|██████████| 1292/1292 [35:20<00:00,  1.64s/it]\n",
      "Validation epoch: 44/1000 Step: 134 loss : 0.3686  accuracy: 0.5564: 100%|██████████| 133/133 [01:46<00:00,  1.25it/s]\n",
      "epoch: 45/1000 Step: 816 loss : 0.1546 accuracy: 1.0000:  63%|██████▎   | 815/1292 [24:25<14:17,  1.80s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m acc_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[1;32m     18\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     19\u001b[0m     count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m image_index:\n\u001b[0;32m---> 19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43mtf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     image_tensor[count] \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     21\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/Image.py:696\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/Image.py:755\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    753\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 755\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/ImageFile.py:305\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_end()\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_exclusive_fp_after_loading:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LOAD_TRUNCATED_IMAGES \u001b[38;5;129;01mand\u001b[39;00m err_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# still raised if decoder fails to return anything\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "sig=nn.Sigmoid()\n",
    "val_acc_list=[]\n",
    "numSample_list = [len(torch.where(torch.tensor(train_label_list)==0.)[0]), len(torch.where(torch.tensor(train_label_list)==1.)[0])]\n",
    "weights = (torch.tensor([1 - (x / sum(numSample_list)) for x in numSample_list])).to(device)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        \n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        enable_running_stats(model)\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = F.cross_entropy(predict.softmax(dim=1), y,weights) # cost 구함\n",
    "        acc=accuracy(predict.softmax(dim=1).argmax(dim=1),y.argmax(dim=1))\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.first_step(zero_grad=False)\n",
    "        disable_running_stats(model)\n",
    "        predict = model(x).to(device)\n",
    "        cost1 = F.cross_entropy(predict.softmax(dim=1), y,weights) # cost 구함\n",
    "        cost1.backward() # cost에 대한 backward 구함\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{1000} Step: {count+1} loss : {running_loss/count:.4f} accuracy: {acc_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "#validation\n",
    "    val=tqdm(validation_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = F.cross_entropy(predict.softmax(dim=1), y,weights) # cost 구함\n",
    "            acc=accuracy(predict.softmax(dim=1).argmax(dim=1),y.argmax(dim=1))\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{1000} Step: {count+1} loss : {val_running_loss/count:.4f}  accuracy: {acc_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "    if epoch%100==5:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='validation_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='validation_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), '../../model/mmrd(MIL)/attention_MIL_callback.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "torch.save(model.state_dict(), '../../model/mmrd(MIL)/attention_MIL.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
